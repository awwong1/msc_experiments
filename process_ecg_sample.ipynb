{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating `ecg_sample_v3.zip`\n",
    "\n",
    "See `ecg_sample/dbo.ECG01.Table.sql`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import glob\n",
    "import zlib\n",
    "\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE [dbems_prodcopy]\n",
      "GO\n",
      "/****** Object:  Table [dbo].[ECG01]    Script Date: 2020-10-20 7:08:09 PM ******/\n",
      "SET ANSI_NULLS ON\n",
      "GO\n",
      "SET QUOTED_IDENTIFIER ON\n",
      "GO\n",
      "CREATE TABLE [dbo].[ECG01](\n",
      "\t[ecgId] [uniqueidentifier] NOT NULL,\n",
      "\t[dateAcquired] [datetime] NOT NULL,\n",
      "\t[dateReceived] [datetime] NOT NULL,\n",
      "\t[dateConfirmed] [datetime] NULL,\n",
      "\t[UserField4] [nvarchar](32) NULL,\n",
      "\t[severityId] [smallint] NULL,\n",
      "\t[headerInfo] [varbinary](4000) NOT NULL,\n",
      "\t[userDefines] [varbinary](4000) NULL,\n",
      "\t[orderInfo] [varbinary](4000) NULL,\n",
      "\t[documentInfo] [varbinary](4000) NOT NULL,\n",
      "\t[reportInfo] [varbinary](4000) NOT NULL,\n",
      "\t[acquisitionInfo] [varbinary](4000) NOT NULL,\n",
      "\t[interpretationInfo] [varbinary](4000) NULL,\n",
      "\t[age] [float] NULL,\n",
      "\t[ageUnits] [tinyint] NULL,\n",
      "\t[Sex] [tinyint] NULL,\n",
      "\t[waveformInfo] [image] NULL,\n",
      "\t[measurementInfo] [varbinary](8000) NULL\n",
      ") ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n",
      "GO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with io.open(\"ecg_sample/dbo.ECG01.Table.sql\", encoding=\"utf-16\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"\".join(lines[:28]))  # anything more is an error\n",
    "inserts = [l for l in lines[28:] if l != \"GO\\n\"]\n",
    "\n",
    "DB_COLS = (\n",
    "    \"ecgId\",\n",
    "    \"dateAcquired\",\n",
    "    \"dateReceived\",\n",
    "    \"dateConfirmed\",\n",
    "    \"UserField4\",\n",
    "    \"severityId\",\n",
    "    \"headerInfo\",\n",
    "    \"userDefines\",\n",
    "    \"orderInfo\",\n",
    "    \"documentInfo\",\n",
    "    \"reportInfo\",\n",
    "    \"acquisitionInfo\",\n",
    "    \"interpretationInfo\",\n",
    "    \"age\",\n",
    "    \"ageUnits\",\n",
    "    \"Sex\",\n",
    "    \"waveformInfo\",\n",
    "    \"measurementInfo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_line_to_payload(raw_line):\n",
    "    line = raw_line.rstrip()\n",
    "    raw_insert, raw_values = line.split(\" VALUES \")\n",
    "    raw_columns = raw_insert[len(\"INSERT [dbo].[ECG01] (\"):len(raw_insert) - len(\")\")]  # raw column names\n",
    "    raw_values = (raw_values[1:len(raw_values) - 1])\n",
    "    \n",
    "    raw_columns = raw_columns.split(\", \")\n",
    "    columns = tuple(col[1:len(col) - 1] for col in raw_columns)  # remove surrounding square braces `[`, `]`\n",
    "    values = raw_values.split(\", \")  # , raw_values.split(\", \"))\n",
    "\n",
    "    assert columns == DB_COLS, \"col mismatch\"\n",
    "    assert len(values) == len(columns), \"not enough values for columns\"\n",
    "\n",
    "    return dict(zip(columns, values))\n",
    "\n",
    "\n",
    "def convert_payload_to_xml(payload):\n",
    "    xml = {}\n",
    "    for key, value in payload.items():\n",
    "        if value.startswith(\"0x\"):\n",
    "            if key == \"waveformInfo\":\n",
    "                val_bytes = zlib.decompress(bytes.fromhex(value[2:]))\n",
    "                xml[key] = val_bytes.decode(\"utf-8\")\n",
    "            else:\n",
    "                val_bytes = zlib.decompress(bytes.fromhex(value[2:]))\n",
    "                xml[key] = val_bytes.decode(\"utf-16\")\n",
    "    return xml\n",
    "\n",
    "\n",
    "def convert_xml_fragments_to_string(xml_fragments):\n",
    "    xml_string = \"\".join([\n",
    "        xml_fragments[\"headerInfo\"],\n",
    "        xml_fragments[\"orderInfo\"],\n",
    "        xml_fragments[\"documentInfo\"],\n",
    "        xml_fragments[\"reportInfo\"],\n",
    "        xml_fragments[\"acquisitionInfo\"],\n",
    "        xml_fragments[\"interpretationInfo\"],\n",
    "        xml_fragments[\"userDefines\"],\n",
    "        xml_fragments[\"measurementInfo\"],\n",
    "        xml_fragments[\"waveformInfo\"],\n",
    "        \"</restingecgdata>\"\n",
    "    ])\n",
    "    return xml_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save_xml(idx_raw_insert):\n",
    "    ins_idx, raw_insert = idx_raw_insert\n",
    "    try:\n",
    "        payload = convert_line_to_payload(raw_insert)\n",
    "        xml_fragments = convert_payload_to_xml(payload)\n",
    "        xml_string = convert_xml_fragments_to_string(xml_fragments)\n",
    "        xml_dom = parseString(xml_string)\n",
    "        \n",
    "        # save to file\n",
    "        ecgId = payload[\"ecgId\"][2:len(payload[\"ecgId\"]) - 1]  # remove enclosing `N'`, `'`\n",
    "        with open(f\"ecg_sample/xml_output/{ecgId}.xml\", \"w\") as f:\n",
    "            f.write(xml_dom.toprettyxml())\n",
    "        return None\n",
    "    except Exception:\n",
    "        return ins_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1960s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 580 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 818 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 900 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 986 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1072 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1162 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1252 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1538 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1636 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2054 out of 2054 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed = joblib.Parallel(n_jobs=-1, verbose=10)(\n",
    "    joblib.delayed(convert_and_save_xml)(idx_raw_insert) for idx_raw_insert in enumerate(inserts)\n",
    ")\n",
    "failed = [fail for fail in failed if fail != None]\n",
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, freeze_support\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PySierraECG import get_leads\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054\n"
     ]
    }
   ],
   "source": [
    "xml_files = glob.glob(\"ecg_sample/xml_output/*.xml\")\n",
    "print(len(xml_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_val(tree, tree_key, p_key=\"globalmeasurements\", ns={\"ns\": \"http://www3.medical.philips.com\"}):\n",
    "    c = tree.find(f\".//ns:{p_key}/ns:{tree_key}\", namespaces=ns)\n",
    "    if c is None:\n",
    "        return None\n",
    "    else:\n",
    "        return c.text\n",
    "\n",
    "\n",
    "def calculate_tick_range(min_y, max_y, step):\n",
    "    y_min_offset = min_y % step\n",
    "    y_max_offset = max_y % step\n",
    "    return range(int(min_y - y_min_offset), int(max_y - y_max_offset + step), step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf(xml_fn, out_dir=\"ecg_sample/pdf_output\", tick_aspect=10/4, main_lead_key=\"II\"):\n",
    "    # check if ecg_id filename is valid\n",
    "    r = re.match(\n",
    "        r\".*(?P<id>[\\w]{8}-[\\w]{4}-[\\w]{4}-[\\w]{4}-[\\w]{12})\\.xml\", xml_fn)\n",
    "    if not r:\n",
    "        return None, None\n",
    "    ecg_id = r.group(\"id\")\n",
    "    \n",
    "    warn = None\n",
    "\n",
    "    # check if we can get the leads from the filename\n",
    "    try:\n",
    "        leads = get_leads(xml_fn)\n",
    "    except Exception as e:\n",
    "        return ecg_id, str(e)\n",
    "\n",
    "    # check if we can load and parse the XML\n",
    "    try:\n",
    "        tree = ET.parse(xml_fn)\n",
    "    except Exception as e:\n",
    "        return ecg_id, str(e)\n",
    "\n",
    "    # check durations and number of samples match the data array\n",
    "    try:\n",
    "        assert len(leads) == 12, \"lead count not equal to 12\"\n",
    "        ref_ms_per_sample = None\n",
    "        names = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\",\n",
    "                 \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "        for lead in leads:\n",
    "            ms_per_sample = lead[\"duration\"] // lead[\"nsamples\"]\n",
    "            if ref_ms_per_sample is None:\n",
    "                ref_ms_per_sample = ms_per_sample\n",
    "            else:\n",
    "                assert ms_per_sample == ref_ms_per_sample, \"ms per sample mismatch\"\n",
    "            x = range(0, lead[\"duration\"], ms_per_sample)\n",
    "            assert len(x) == lead[\"nsamples\"], \"duration nsamples mismatch\"\n",
    "            assert lead[\"name\"] in names, f\"invalid lead name: {lead['name']}\"\n",
    "            # assert max(lead['data']) <= 1000, \"WARN: lead signal max over 5mV\"\n",
    "            # assert min(lead['data']) >= -1000, \"WARN: lead signal min under -5mV\"\n",
    "            names.pop(names.index(lead[\"name\"]))\n",
    "    except Exception as e:\n",
    "        return ecg_id, str(e)\n",
    "    finally:\n",
    "        del names\n",
    "        del ref_ms_per_sample\n",
    "\n",
    "    leads_dict = {}\n",
    "    while leads:\n",
    "        lead = leads.pop()\n",
    "        name = lead.pop(\"name\")\n",
    "        leads_dict[name] = lead[\"data\"]\n",
    "    del leads\n",
    "    del name\n",
    "\n",
    "    # according to the calibration signal, 0-200 is equal to 1mV\n",
    "    # we want to make a grid where all of the ticks are in millimeters\n",
    "    # standard calibration: 10mm/mv (y-axis), 25mm/sec (x-axis)\n",
    "    # y: 5mm == 100 units; x: 5mm == 40 ms\n",
    "\n",
    "    # I,   aVR, V1, V4\n",
    "    # II,  aVL, V2, V5\n",
    "    # III, aVF, V3, V6\n",
    "    # II\n",
    "\n",
    "    q_x = len(x) // 4   # plot column separator width\n",
    "    q_y = 600           # plot row separator height\n",
    "\n",
    "    plot_leads = {\n",
    "        \"MAIN\": leads_dict[main_lead_key],\n",
    "        \"I\":    [v + 3 * q_y for v in leads_dict[\"I\"]][:q_x],\n",
    "        \"II\":   [v + 2 * q_y for v in leads_dict[\"II\"]][:q_x],\n",
    "        \"III\":  [v + 1 * q_y for v in leads_dict[\"III\"]][:q_x],\n",
    "        \"aVR\":  [v + 3 * q_y for v in leads_dict[\"aVR\"]][q_x:2 * q_x],\n",
    "        \"aVL\":  [v + 2 * q_y for v in leads_dict[\"aVL\"]][q_x:2 * q_x],\n",
    "        \"aVF\":  [v + 1 * q_y for v in leads_dict[\"aVF\"]][q_x:2 * q_x],\n",
    "        \"V1\":   [v + 3 * q_y for v in leads_dict[\"V1\"]][2 * q_x:3 * q_x],\n",
    "        \"V2\":   [v + 2 * q_y for v in leads_dict[\"V2\"]][2 * q_x:3 * q_x],\n",
    "        \"V3\":   [v + 1 * q_y for v in leads_dict[\"V3\"]][2 * q_x:3 * q_x],\n",
    "        \"V4\":   [v + 3 * q_y for v in leads_dict[\"V4\"]][3 * q_x:4 * q_x],\n",
    "        \"V5\":   [v + 2 * q_y for v in leads_dict[\"V5\"]][3 * q_x:4 * q_x],\n",
    "        \"V6\":   [v + 1 * q_y for v in leads_dict[\"V6\"]][3 * q_x:4 * q_x]\n",
    "    }\n",
    "\n",
    "    # some of the data has signals that are extreme outliers and overlap over the other leads\n",
    "    y_min = min([min(l) for l in plot_leads.values()])\n",
    "    y_max = max([max(l) for l in plot_leads.values()])\n",
    "    x = range(0, lead[\"duration\"], lead[\"duration\"] // lead[\"nsamples\"])\n",
    "\n",
    "    # if the scaled ecg signal y-axis is longer than the time x-axis, that's an error (breaks all text)\n",
    "    if (y_max - y_min) * (tick_aspect) > max(x):\n",
    "        # return ecg_id, \"mv signal has greater distribution than allowable ms time range\"\n",
    "        warn = \"WARN: mv signal has greater distribution than allowable ms time range\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5 * 2, 8.0 * 2), dpi=300)\n",
    "    ax.plot(x, plot_leads[\"MAIN\"])\n",
    "    ax.set_xticks(range(0, max(x)+1, 40), minor=True)\n",
    "    ax.set_xticks(range(0, max(x)+1, 200), minor=False)\n",
    "\n",
    "    # plot columns [I, II, III]\n",
    "    ax.plot(x[:q_x], plot_leads[\"I\"])\n",
    "    ax.plot(x[:q_x], plot_leads[\"II\"])\n",
    "    ax.plot(x[:q_x], plot_leads[\"III\"])\n",
    "    # plot columns [aVR, aVL, aVF]\n",
    "    ax.plot(x[q_x:2 * q_x], plot_leads[\"aVR\"])\n",
    "    ax.plot(x[q_x:2 * q_x], plot_leads[\"aVL\"])\n",
    "    ax.plot(x[q_x:2 * q_x], plot_leads[\"aVF\"])\n",
    "    # plot columns [V1, V2, V3]\n",
    "    ax.plot(x[2 * q_x:3 * q_x], plot_leads[\"V1\"])\n",
    "    ax.plot(x[2 * q_x:3 * q_x], plot_leads[\"V2\"])\n",
    "    ax.plot(x[2 * q_x:3 * q_x], plot_leads[\"V3\"])\n",
    "    # plot columns [V4, V5, V6]\n",
    "    ax.plot(x[3 * q_x:4 * q_x], plot_leads[\"V4\"])\n",
    "    ax.plot(x[3 * q_x:4 * q_x], plot_leads[\"V5\"])\n",
    "    ax.plot(x[3 * q_x:4 * q_x], plot_leads[\"V6\"])\n",
    "\n",
    "    # set label text for each lead\n",
    "    q_xd = max(x) // 4\n",
    "    text_kwargs = {\"horizontalalignment\": \"left\",\n",
    "                   \"verticalalignment\": \"top\", \"fontsize\": 14}\n",
    "    ax.text(0 * q_xd, 0 * q_y + 200, main_lead_key, **text_kwargs)  # MAIN\n",
    "    ax.text(0 * q_xd, 3 * q_y + 200, \"I\", **text_kwargs)\n",
    "    ax.text(0 * q_xd, 2 * q_y + 200, \"II\", **text_kwargs)\n",
    "    ax.text(0 * q_xd, 1 * q_y + 200, \"III\", **text_kwargs)\n",
    "    ax.text(1 * q_xd, 3 * q_y + 200, \"aVR\", **text_kwargs)\n",
    "    ax.text(1 * q_xd, 2 * q_y + 200, \"aVL\", **text_kwargs)\n",
    "    ax.text(1 * q_xd, 1 * q_y + 200, \"aVF\", **text_kwargs)\n",
    "    ax.text(2 * q_xd, 3 * q_y + 200, \"V1\", **text_kwargs)\n",
    "    ax.text(2 * q_xd, 2 * q_y + 200, \"V2\", **text_kwargs)\n",
    "    ax.text(2 * q_xd, 1 * q_y + 200, \"V3\", **text_kwargs)\n",
    "    ax.text(3 * q_xd, 3 * q_y + 200, \"V4\", **text_kwargs)\n",
    "    ax.text(3 * q_xd, 2 * q_y + 200, \"V5\", **text_kwargs)\n",
    "    ax.text(3 * q_xd, 1 * q_y + 200, \"V6\", **text_kwargs)\n",
    "\n",
    "    # major y-ticks every 100, minor y-ticks every 20. major ticks aligned to 0\n",
    "    # ax.set_yticks(range(-100, 250+1, 20), minor=True)\n",
    "    # ax.set_yticks(range(-100, 250+1, 100), minor=False)\n",
    "    ax.set_yticks(calculate_tick_range(y_min, y_max, 20), minor=True)\n",
    "    ax.set_yticks(calculate_tick_range(y_min, y_max, 100), minor=False)\n",
    "    ax.set_xticklabels(())\n",
    "    ax.set_yticklabels(())\n",
    "\n",
    "    # set the gridlines\n",
    "    ax.grid(b=True, which=\"major\", axis=\"both\",\n",
    "            color=\"pink\", linestyle=\"solid\", linewidth=1.5)\n",
    "    ax.grid(b=True, which=\"minor\", axis=\"both\",\n",
    "            color=\"pink\", linestyle=\"solid\", linewidth=0.5)\n",
    "\n",
    "    # force aspect ratio to have gridlines square box shaped\n",
    "    ax.set_aspect(tick_aspect)\n",
    "    plt.margins(0.01)\n",
    "\n",
    "    ax.set_xlabel(\"25 ticks/second\")\n",
    "    ax.set_ylabel(\"10 ticks/mV\")\n",
    "\n",
    "    # hardcoded text metadata, assumes 11000 millisecond duration for x-axis offset\n",
    "    x_off = 0\n",
    "    text_kwargs = {\"horizontalalignment\": \"left\",\n",
    "                   \"verticalalignment\": \"bottom\", \"fontsize\": 10}\n",
    "    ns = {\"ns\": \"http://www3.medical.philips.com\"}\n",
    "\n",
    "    # construct acquisition & patient information\n",
    "    ecg_metadata = f\"ecgId: {ecg_id}\\n\"\n",
    "    ecg_metadata += \"\\nAcquisition\"\n",
    "    ecg_metadata += \"\\n  Date:\"\n",
    "    ecg_metadata += \"\\n  Time:\"\n",
    "    ecg_metadata += \"\\nPatient ID:\"\n",
    "    ecg_metadata += \"\\nBirth Date:\"\n",
    "    ecg_metadata += \"\\nSex:\"\n",
    "    ecg_metadata += \"\\nHeight:\"\n",
    "    ecg_metadata += \"\\nWeight:\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 650\n",
    "\n",
    "    patientid = get_tree_val(tree, \"patientid\", p_key=\"generalpatientdata\")\n",
    "    acq_node = tree.find(\"./ns:dataacquisition\", namespaces=ns)\n",
    "    acq_date = acq_node.attrib.get(\"date\", None)\n",
    "    acq_time = acq_node.attrib.get(\"time\", None)\n",
    "    ecg_metadata = f\"\\n{acq_date}\\n{acq_time}\"\n",
    "    ecg_metadata += f\"\\n{patientid}\"\n",
    "    dateofbirth = get_tree_val(tree, \"dateofbirth\", p_key=\"age\")\n",
    "    ecg_metadata += f\"\\n{dateofbirth}\"\n",
    "    sex = get_tree_val(tree, \"sex\", p_key=\"generalpatientdata\")\n",
    "    ecg_metadata += f\"\\n{sex}\"\n",
    "    height = get_tree_val(tree, \"cm\", p_key=\"height\")\n",
    "    ecg_metadata += f\"\\n{height} cm\"\n",
    "    weight = get_tree_val(tree, \"kg\", p_key=\"weight\")\n",
    "    ecg_metadata += f\"\\n{weight} kg\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 850\n",
    "\n",
    "    # construct duration\n",
    "    ecg_metadata = \"\\nRR Interval:\"\n",
    "    ecg_metadata += \"\\nP Duration:\"\n",
    "    ecg_metadata += \"\\nPR Interval:\"\n",
    "    ecg_metadata += \"\\nQRS Duration:\"\n",
    "    ecg_metadata += \"\\nQT Interval:\"\n",
    "    ecg_metadata += \"\\nQTCb:\"\n",
    "    ecg_metadata += \"\\nQTCf:\"\n",
    "    ecg_metadata += \"\\nQ Onset:\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 750\n",
    "    rrint = get_tree_val(tree, \"rrint\")\n",
    "    ecg_metadata = f\"\\n{rrint} ms\"\n",
    "    pdur = get_tree_val(tree, \"pdur\")\n",
    "    ecg_metadata += f\"\\n{pdur} ms\"\n",
    "    pr_int = get_tree_val(tree, \"print\")\n",
    "    ecg_metadata += f\"\\n{pr_int} ms\"\n",
    "    qrs_dur = get_tree_val(tree, \"qrsdur\")\n",
    "    ecg_metadata += f\"\\n{qrs_dur} ms\"\n",
    "    qt_int = get_tree_val(tree, \"qtint\")\n",
    "    ecg_metadata += f\"\\n{qt_int} ms\"\n",
    "    qtcb = get_tree_val(tree, \"qtcb\")\n",
    "    ecg_metadata += f\"\\n{qtcb} ms\"\n",
    "    qtcf = get_tree_val(tree, \"qtcf\")\n",
    "    ecg_metadata += f\"\\n{qtcf} ms\"\n",
    "    qonset = get_tree_val(tree, \"qonset\")\n",
    "    ecg_metadata += f\"\\n{qonset} ms\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 800\n",
    "\n",
    "    # construct frontaxis\n",
    "    ecg_metadata = \"Heart rate:\\n\"\n",
    "    ecg_metadata += \"\\nP Front Axis:\"\n",
    "    ecg_metadata += \"\\ni40 Front Axis:\"\n",
    "    ecg_metadata += \"\\nt40 Front Axis:\"\n",
    "    ecg_metadata += \"\\nQRS Front Axis:\"\n",
    "    ecg_metadata += \"\\nST Front Axis:\"\n",
    "    ecg_metadata += \"\\nT Front Axis:\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 800\n",
    "    heartrate = get_tree_val(tree, \"heartrate\")\n",
    "    ecg_metadata = f\"{heartrate} BPM\\n\"\n",
    "    pfrontaxis = get_tree_val(tree, \"pfrontaxis\")\n",
    "    ecg_metadata += f\"\\n{pfrontaxis}°\"\n",
    "    i40frontaxis = get_tree_val(tree, \"i40frontaxis\")\n",
    "    ecg_metadata += f\"\\n{i40frontaxis}°\"\n",
    "    t40frontaxis = get_tree_val(tree, \"t40frontaxis\")\n",
    "    ecg_metadata += f\"\\n{i40frontaxis}°\"\n",
    "    qrsfrontaxis = get_tree_val(tree, \"qrsfrontaxis\")\n",
    "    ecg_metadata += f\"\\n{qrsfrontaxis}°\"\n",
    "    stfrontaxis = get_tree_val(tree, \"stfrontaxis\")\n",
    "    ecg_metadata += f\"\\n{stfrontaxis}°\"\n",
    "    tfrontaxis = get_tree_val(tree, \"tfrontaxis\")\n",
    "    ecg_metadata += f\"\\n{i40frontaxis}°\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 800\n",
    "\n",
    "    # construct horizaxis\n",
    "    ecg_metadata = \"Atrial rate:\\n\"\n",
    "    ecg_metadata += \"\\nP Horiz. Axis:\"\n",
    "    ecg_metadata += \"\\ni40 Horiz. Axis:\"\n",
    "    ecg_metadata += \"\\nt40 Horiz. Axis:\"\n",
    "    ecg_metadata += \"\\nQRS Horiz. Axis:\"\n",
    "    ecg_metadata += \"\\nST Horiz. Axis:\"\n",
    "    ecg_metadata += \"\\nT Horiz. Axis:\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 800\n",
    "    atrialrate = get_tree_val(tree, \"atrialrate\")\n",
    "    ecg_metadata = f\"{atrialrate} BPM\\n\"\n",
    "    phorizaxis = get_tree_val(tree, \"phorizaxis\")\n",
    "    ecg_metadata += f\"\\n{phorizaxis}°\"\n",
    "    i40horizaxis = get_tree_val(tree, \"i40horizaxis\")\n",
    "    ecg_metadata += f\"\\n{i40horizaxis}°\"\n",
    "    t40horizaxis = get_tree_val(tree, \"t40horizaxis\")\n",
    "    ecg_metadata += f\"\\n{i40horizaxis}°\"\n",
    "    qrshorizaxis = get_tree_val(tree, \"qrshorizaxis\")\n",
    "    ecg_metadata += f\"\\n{qrshorizaxis}°\"\n",
    "    sthorizaxis = get_tree_val(tree, \"sthorizaxis\")\n",
    "    ecg_metadata += f\"\\n{sthorizaxis}°\"\n",
    "    thorizaxis = get_tree_val(tree, \"thorizaxis\")\n",
    "    ecg_metadata += f\"\\n{i40horizaxis}°\"\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "    x_off += 800\n",
    "\n",
    "    # construct severity and codes\n",
    "    severity = get_tree_val(tree, \"severity\", p_key=\"interpretation\")\n",
    "    ecg_metadata = f\"{severity}\\n\"\n",
    "    mdsignatureline = get_tree_val(tree, \"mdsignatureline\", p_key=\"interpretation\")\n",
    "    ecg_metadata += f\"{mdsignatureline}\\n\"\n",
    "    codes = zip(\n",
    "        [x.text or \"\" for x in tree.findall(\n",
    "            f\".//ns:statement/ns:statementcode\", namespaces=ns)],\n",
    "        [x.text or \"\" for x in tree.findall(\n",
    "            f\".//ns:statement/ns:leftstatement\", namespaces=ns)],\n",
    "        [x.text or \"\" for x in tree.findall(\n",
    "            f\".//ns:statement/ns:rightstatement\", namespaces=ns)]\n",
    "    )\n",
    "    for code in codes:\n",
    "        ecg_metadata += \"\\n\" + \" \".join(code)\n",
    "    ax.text(x_off, y_max + 50, ecg_metadata, **text_kwargs)\n",
    "\n",
    "    # plt.show()\n",
    "    fig_name = os.path.join(out_dir, f\"{ecg_id}.pdf\")\n",
    "    fig.savefig(fig_name, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close(fig)\n",
    "    return ecg_id, warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 649 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 733 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 821 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 913 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1058 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1109 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1160 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1213 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1321 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1433 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1490 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1549 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1608 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1669 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1730 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1793 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1856 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2054 out of 2054 | elapsed:   57.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'c766c180-f408-11e7-4823-0005039b0029': 'WARN: mv signal has greater distribution than allowable ms time range',\n",
       " '52737a80-f296-11e7-4823-001943f70029': 'WARN: mv signal has greater distribution than allowable ms time range',\n",
       " '9172e300-f238-11e7-4823-0005ee5d0029': 'WARN: mv signal has greater distribution than allowable ms time range',\n",
       " 'b440fb00-f3e2-11e7-4823-0004c2b00029': 'WARN: mv signal has greater distribution than allowable ms time range'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_gen_output = joblib.Parallel(n_jobs=-1, verbose=10)(\n",
    "    joblib.delayed(generate_pdf)(xml_fp) for xml_fp in xml_files\n",
    ")\n",
    "pdf_gen_output = dict(pdf_gen_output)\n",
    "# pdf_gen_output\n",
    "# failed = dict(()\n",
    "# failed\n",
    "warn_fail = dict((k, v) for (k, v) in pdf_gen_output.items() if v != None)\n",
    "warn_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

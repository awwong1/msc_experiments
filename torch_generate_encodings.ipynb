{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate signal encoding/embeddings\n",
    "\n",
    "For the thesis final experiment, fusing autoencoders with XGB decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import takewhile\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import zarr\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import ElapsedTimer\n",
    "from datasets.SequenceZarr import SequenceZarr\n",
    "from sequence_autoencoder import SequenceAutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── beats\n",
      " │   ├── r_peak_idxs (43099,) object\n",
      " │   ├── valid_r_peak_idxs (43099,) object\n",
      " │   ├── window_size_400 (43099,) object\n",
      " │   ├── window_size_400_normalized (43099,) object\n",
      " │   ├── window_size_400_normalized_flattened (801266, 400, 12) float32\n",
      " │   ├── window_size_400_outlier (43099,) int32\n",
      " │   └── window_size_400_shape (43099, 3) int32\n",
      " ├── cleaned\n",
      " │   └── p_signal (43099,) object\n",
      " ├── meta\n",
      " │   └── record_idx_to_window_400_range (1,) object\n",
      " ├── raw\n",
      " │   ├── dx (43099,) object\n",
      " │   ├── meta (43099, 3) int32\n",
      " │   ├── p_signal (43099,) object\n",
      " │   └── p_signal_shape (43099, 2) int32\n",
      " └── seq_embeddings\n",
      "     ├── version_0 (43099, 768) float64\n",
      "     ├── version_1 (43099, 768) float64\n",
      "     ├── version_10 (43099, 768) float64\n",
      "     ├── version_11 (43099, 768) float64\n",
      "     ├── version_12 (43099, 768) float64\n",
      "     ├── version_13 (43099, 768) float64\n",
      "     ├── version_14 (43099, 768) float64\n",
      "     ├── version_15 (43099, 768) float64\n",
      "     ├── version_16 (43099, 768) float64\n",
      "     ├── version_17 (43099, 768) float64\n",
      "     ├── version_18 (43099, 768) float64\n",
      "     ├── version_19 (43099, 768) float64\n",
      "     ├── version_2 (43099, 768) float64\n",
      "     ├── version_3 (43099, 768) float64\n",
      "     ├── version_4 (43099, 768) float64\n",
      "     ├── version_5 (43099, 768) float64\n",
      "     ├── version_6 (43099, 768) float64\n",
      "     ├── version_7 (43099, 768) float64\n",
      "     ├── version_8 (43099, 768) float64\n",
      "     └── version_9 (43099, 768) float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexwong/miniconda3/envs/msc_research/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:994: UserWarning: unknown class(es) [111288001, 11157007, 13640000, 164861001, 164865005, 164867002, 164873001, 164884008, 164895002, 164896001, 164921003, 164930006, 164931005, 164937009, 164951009, 195042002, 195060002, 195080001, 195101003, 195126007, 204384007, 233917008, 251120003, 251139008, 251164006, 251168009, 251170000, 251173003, 251180001, 251182009, 251200008, 251259000, 251266004, 251268003, 253339007, 253352002, 266249003, 266257000, 27885002, 282825002, 29320008, 314208002, 368009, 370365005, 413444003, 413844008, 425419005, 425623009, 425856008, 426434006, 426648003, 426664006, 426749004, 426761007, 426995002, 428417006, 428750005, 429622005, 445211001, 446358003, 446813000, 49260003, 49578007, 53741008, 54016002, 54329005, 55930002, 57054005, 60423000, 6374002, 65778007, 67198005, 698247007, 704997005, 713422000, 74390002, 74615001, 75532003, 775926597, 77867006, 81898007, 82226007, 84114007, 89792004] will be ignored\n",
      "  warnings.warn('unknown class(es) {0} will be ignored'\n"
     ]
    }
   ],
   "source": [
    "# initialize zarr group\n",
    "# root = zarr.open_group(\"data/ecgs.zarr\", mode=\"r\")\n",
    "\n",
    "store = zarr.DirectoryStore(\"data/ecgs.zarr\")\n",
    "root = zarr.group(store=store)\n",
    "seq_embeddings = root.require_group(\"seq_embeddings\")\n",
    "print(root.tree())\n",
    "# root.info\n",
    "\n",
    "ds = SequenceZarr(sequence_length=20)\n",
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    "    collate_fn=SequenceZarr.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_beat_checkpoints = glob(\"log_beat_autoencoder/*/checkpoints/*.ckpt\")\n",
    "torch_seq_checkpoints = glob(\"log_sequence_autoencoder/*/*.ckpt\")\n",
    "\n",
    "beat_seq_checkpoints = list(zip(sorted(torch_beat_checkpoints), sorted(torch_seq_checkpoints)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq_embeddings(beat_seq_checkpoint):\n",
    "    beat_checkpoint, seq_checkpoint = beat_seq_checkpoint\n",
    "    version_str = beat_checkpoint.split(\"/\")[1]\n",
    "    model = SequenceAutoEncoder.load_from_checkpoint(seq_checkpoint)\n",
    "    model.cuda()\n",
    "    iter_dl = iter(dl)\n",
    "    \n",
    "    embeddings = []\n",
    "    counter = 0\n",
    "    while True:\n",
    "        try:\n",
    "            counter += 1\n",
    "            batch = next(iter_dl)\n",
    "            beat_windows, seq_lens, dxs, str_abbrv_dxs, str_code_dxs = batch\n",
    "            beat_windows = [bw.cuda() for bw in beat_windows]\n",
    "            _pred_classes, embedding, _x_source, _x_hat = model(beat_windows, seq_lens)\n",
    "            embeddings.append(embedding.detach().cpu().numpy())\n",
    "        except StopIteration:\n",
    "            break\n",
    "        finally:\n",
    "            if counter % 7 == 0:\n",
    "                print(counter, end=\"\\r\")\n",
    "    print(len(embeddings))\n",
    "    return np.concatenate(embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0\n",
      "337\n",
      "took 85.97 seconds\n",
      "version_1\n",
      "337\n",
      "took 82.47 seconds\n",
      "version_10\n",
      "337\n",
      "took 80.63 seconds\n",
      "version_11\n",
      "337\n",
      "took 80.83 seconds\n",
      "version_12\n",
      "337\n",
      "took 81.73 seconds\n",
      "version_13\n",
      "337\n",
      "took 80.99 seconds\n",
      "version_14\n",
      "337\n",
      "took 81.82 seconds\n",
      "version_15\n",
      "337\n",
      "took 82.61 seconds\n",
      "version_16\n",
      "337\n",
      "took 81.33 seconds\n",
      "version_17\n",
      "337\n",
      "took 80.20 seconds\n",
      "version_18\n",
      "337\n",
      "took 81.81 seconds\n",
      "version_19\n",
      "337\n",
      "took 80.64 seconds\n",
      "version_2\n",
      "337\n",
      "took 81.04 seconds\n",
      "version_3\n",
      "337\n",
      "took 81.62 seconds\n",
      "version_4\n",
      "337\n",
      "took 82.01 seconds\n",
      "version_5\n",
      "337\n",
      "took 82.02 seconds\n",
      "version_6\n",
      "337\n",
      "took 82.16 seconds\n",
      "version_7\n",
      "337\n",
      "took 82.83 seconds\n",
      "version_8\n",
      "337\n",
      "took 82.62 seconds\n",
      "version_9\n",
      "337\n",
      "took 81.74 seconds\n"
     ]
    }
   ],
   "source": [
    "for beat_seq_checkpoint in beat_seq_checkpoints:\n",
    "    with ElapsedTimer() as t:\n",
    "        version_str = beat_seq_checkpoint[0].split(\"/\")[1]\n",
    "        print(version_str)\n",
    "        embd_container = seq_embeddings.empty(\n",
    "            version_str,\n",
    "            shape=(len(ds), 768),\n",
    "            chunks=(1, 768)\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            embeddings = generate_seq_embeddings(beat_seq_checkpoint)\n",
    "\n",
    "        embd_container[:] = embeddings\n",
    "    print(f\"took {t.duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
